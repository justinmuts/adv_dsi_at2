{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQ6wc2HE0pke"
   },
   "source": [
    "# **Lab: Unstructured Data**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQgxLRrvjiJb"
   },
   "source": [
    "## Exercise 3: Text Classification\n",
    "\n",
    "In this exercise, we will train a Pytorch model with embeddings for classifying texts into topics. We will be working on the DBpedia dataset:\n",
    "https://wiki.dbpedia.org/about\n",
    "\n",
    "The steps are:\n",
    "1.   Setup Repository\n",
    "2.   Load Dataset\n",
    "3.   Prepare Data\n",
    "4.   Define Architecture\n",
    "5.   Train Model\n",
    "6.   Push Changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smh_LhVjIg9s"
   },
   "source": [
    "### 1. Setup Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fTLEcebNjhz"
   },
   "source": [
    "**[1.1]** Go inside the created folder `adv_dsi_lab_6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pe-loIVTNjqW"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Go inside the created folder adv_dsi_lab_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHPUrI1Cu-g-"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "cd adv_dsi_lab_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHQBJUHEQqcs"
   },
   "source": [
    "**[1.2]** Create a new git branch called pytorch_dbpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bM-1oZYxQqmO"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Create a new git branch called pytorch_dbpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbseMHf7Qqo2"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "git checkout -b pytorch_dbpedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urrLvZmTUX23"
   },
   "source": [
    "**[1.3]** Run the built image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDAwl-fSVgIe"
   },
   "outputs": [],
   "source": [
    "docker run  -dit --rm --name adv_dsi_lab_6 -p 8888:8888 -e JUPYTER_ENABLE_LAB=yes -v ~/Projects/adv_dsi/adv_dsi_lab_6:/home/jovyan/work -v ~/Projects/adv_dsi/src:/home/jovyan/work/src pytorch-notebook:latest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fO9RJMhwGpM"
   },
   "source": [
    "**[1.4]** Display last 50 lines of logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwizA-K3wGyb"
   },
   "outputs": [],
   "source": [
    "docker logs --tail 50 adv_dsi_lab_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxkJaPioCmEO"
   },
   "source": [
    "Copy the url displayed and paste it to a browser in order to launch Jupyter Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTjwF_joDWnE"
   },
   "source": [
    "**[1.6]** Navigate the folder `notebooks` and create a new jupyter notebook called `3_pytorch_dbpedia.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NCwQQFkU3v5"
   },
   "source": [
    "### 2.   Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "I46331S9lMXF",
    "outputId": "706bb28c-a3ea-47a7-8d66-2c9da981ff0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.7.1+cpu\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torch-1.7.1%2Bcpu-cp37-cp37m-linux_x86_64.whl (159.4MB)\n",
      "\u001b[K     |████████████████████████████████| 159.4MB 76kB/s \n",
      "\u001b[?25hCollecting torchvision==0.8.2+cpu\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.8.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (11.8MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8MB 33.6MB/s \n",
      "\u001b[?25hCollecting torchtext==0.8.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/80/046f0691b296e755ae884df3ca98033cb9afcaf287603b2b7999e94640b8/torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0MB 4.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cpu) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cpu) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cpu) (7.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
      "Installing collected packages: torch, torchvision, torchtext\n",
      "  Found existing installation: torch 1.7.1+cu101\n",
      "    Uninstalling torch-1.7.1+cu101:\n",
      "      Successfully uninstalled torch-1.7.1+cu101\n",
      "  Found existing installation: torchvision 0.8.2+cu101\n",
      "    Uninstalling torchvision-0.8.2+cu101:\n",
      "      Successfully uninstalled torchvision-0.8.2+cu101\n",
      "  Found existing installation: torchtext 0.3.1\n",
      "    Uninstalling torchtext-0.3.1:\n",
      "      Successfully uninstalled torchtext-0.3.1\n",
      "Successfully installed torch-1.7.1+cpu torchtext-0.8.1 torchvision-0.8.2+cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "torch",
         "torchtext"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbRDgod3_3Yv"
   },
   "source": [
    "**[2.1]** Import torch, torchtext and text_classification from torchtext.datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLb163oq_3iR"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (3 lines of Python code)\n",
    "# Task: Import torch and torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcaDN6V3_3q9"
   },
   "outputs": [],
   "source": [
    "#Solution\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import text_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Zy6Oq8pkuB"
   },
   "source": [
    "**[2.2]** Create 2 variables called `NGRAMS` and `BATCH_SIZE` that will contain respectively the values 2 and 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q45yJsSqUJ9t"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (2 lines of Python code)\n",
    "# Task: Create 2 variables called NGRAMS and BATCH_SIZE that will contain respectively the values 2 and 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1iETWjDftMg"
   },
   "outputs": [],
   "source": [
    "#Solution\n",
    "NGRAMS = 2\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLyMcoNCsx2k"
   },
   "source": [
    "**[2.3]** Dowload DBpedia dataset into `data/raw/` folder with 2 ngrams and no vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VCZmDmWVPLf",
    "outputId": "10c6a859-185b-4193-e43b-447ae1eca1fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dbpedia_csv.tar.gz: 68.3MB [00:00, 110MB/s] \n",
      "560000lines [01:03, 8782.51lines/s]\n",
      "560000lines [01:51, 5013.94lines/s]\n",
      "70000lines [00:14, 4714.07lines/s]\n"
     ]
    }
   ],
   "source": [
    "#train_dataset, test_dataset = text_classification.DATASETS['DBpedia'](root='../data/raw', ngrams=NGRAMS, vocab=None)\n",
    "train_dataset, test_dataset = text_classification.DATASETS['DBpedia'](root='./data/raw', ngrams=NGRAMS, vocab=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQgeYjQDs12m"
   },
   "source": [
    "**[2.4]** Print the length of the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOA7T87hs19l"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (2 lines of Python code)\n",
    "# Task: Print the length of the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg_89DlAs1_w",
    "outputId": "185ce806-9368-40a9-a4b1-b176dca36cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miQ6SiKlscLx"
   },
   "source": [
    "### 3. Prepare Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtuF1V6ctwn-"
   },
   "source": [
    "**[3.1]** Extract the size of the vocabulary from the training set and save it into a variable called `VOCAB_SIZE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zqaz1C7DtwuU"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Extract the size of the vocabulary from the training set and save it into a variable called VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrXR7NCLtwxB"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "VOCAB_SIZE = len(train_dataset.get_vocab())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OivZmG19WLF2"
   },
   "source": [
    "**[3.2]** Extract the number of classes from the training set and save it into a variable called `NUM_CLASS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2F2CkjaWLOE"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Extract the number of classes from the training set and save it into a variable called NUM_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-z1sH-7_WLST"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "NUM_CLASS = len(train_dataset.get_labels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "femTzeCBN0Wf"
   },
   "source": [
    "**[3.3]** Import random_split from torch.utils.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Y3VOTNPN0id"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Import random_split from torch.utils.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgrFk1bhN0qO"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1RrTCBRDybQ"
   },
   "source": [
    "**[3.4]** Create 2 variables called `train_len` and `valid_len` that will  contain values that represent respectively 95% and 5% of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtYjKp_1DyiT"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (2 lines of Python code)\n",
    "# Task: Create 2 variables called train_len and valid_len that will contain values that represent respectively 95% and 5% of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aezRs9S3Dyl0"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "train_len = int(len(train_dataset) * 0.95)\n",
    "valid_len = len(train_dataset) - train_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pKaCxasERAt"
   },
   "source": [
    "**[3.5]** Split the training data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbqcA0Lg0Nqa"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Split the training data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDwCmIXvERJO"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "train_data, valid_data = random_split(train_dataset, [train_len, valid_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l0Hkri1FVrv"
   },
   "source": [
    "**[3.6]** Create a generator on `train_data` and extract the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVRRa_nJX9fk"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (2 lines of Python code)\n",
    "# Task: Create a generator on train_data and extract the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_yCjMqgFV1u"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "examples = enumerate(train_data)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPlrX3uL4GjM",
    "outputId": "188103ad-e28b-49e9-b0c8-50f72107c624"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  34887,  330820, 3255093,     238,   16441,       2,  176676,  170439,\n",
       "          20850,  330820,     238,      70,     311,    1154,    2684,   16441,\n",
       "            238,       7,       6,     490,    3578,   28181,     902,   11034,\n",
       "        4244776,     169,   10188,    1734,     441,       4,     411,       2,\n",
       "            644,       5,    1154,       8,     311,    1154,       3,    2536,\n",
       "         404551,     398,    1690,    2047,      20,  119286,     169,   52648,\n",
       "              3, 3242498, 2339510, 3255094,  568496,  302357,  239112,  176677,\n",
       "         178204, 6217895, 2339509,   77267,   87365,    5743,  315091, 5208092,\n",
       "        2348866,   11687,      11,   10422,    8447,   47942,   36810, 3489086,\n",
       "        3583243, 4244777, 5452755,   20246,   52947,    3465,    3281,    3261,\n",
       "           2915,    1266,    7727,   12026,    4009,    5743,    3303, 1210135,\n",
       "        5450200, 5990363,  582316,  357302,  438135,  677244,  219862, 5452431,\n",
       "         411325])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2v1vLMWTofp"
   },
   "source": [
    "**[3.7]** Define a function that will extract label and target from a batch of observation, calculate the length of each text and store them as offset (highlight start of new text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcTo7drqTom4"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (multiple lines of Python code)\n",
    "# Task: Print the dimensions of the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfUpbRYSTopS"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text = [entry[1] for entry in batch]\n",
    "    \n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8MNBrC4Zgz6"
   },
   "source": [
    "### 4. Define Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Lt1lE8lJ9zS"
   },
   "source": [
    "**[4.1]** Import torch.nn as nn and torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kc6UHpDqJ96o"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (2 lines of Python code)\n",
    "# Task: Import torch.nn as nn and torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xufkK8VJ99s"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFCSRIyMZuAR"
   },
   "source": [
    "**[4.2]** Create a class called `TextTopic` that inherits from `nn.Module` with:\n",
    "- inputs:\n",
    "    - vocabulary size\n",
    "    - embedding dimension\n",
    "    - number of classes\n",
    "- attributes:\n",
    "    - `embedding`: bag of embedding of shape: vocabulary size * embedding dimension \n",
    "    - `fc`: fully-connected layer with the number of neurons equals to the number of classes\n",
    "    - `softmax`: Softmax activation function\n",
    "- methods:\n",
    "    - `forward()` with `text` and `offsets` as input parameters and will sequentially add the embedding layer with dropout followed by the fully connected layer with dropout and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00BWv65bZg7C"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (multiple lines of Python code)\n",
    "# Task: Create a class called TextTopic that inherits from nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eejq-COGZhCP"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "class TextTopic(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        x = F.dropout(self.embedding(text, offsets), 0.3)\n",
    "        x = F.dropout(self.fc(x), 0.3)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJNZfvA4dJ9X"
   },
   "source": [
    "**[4.3]** Create a variable called `EMBED_DIM` that will contain the value 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rdui0TivdKGE"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Create a variable called EMBED_DIM that will contain the value 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fev4FWAYdU1G"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "EMBED_DIM = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRLIZeci7cfW"
   },
   "source": [
    "**[4.4]** Instantiate a `TextTopic()` and save it into a variable called `model` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QehpZw7n7coW"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Instantiate a TextTopic() and save it into a variable called model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1Jt8WX57cqn"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "model = TextTopic(VOCAB_SIZE, EMBED_DIM, NUM_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyV4P9b_LML4"
   },
   "source": [
    "**[4.5]** Import the `get_device` function from src.models.pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J65SAKbDLMRr"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Import the get_device function from src.models.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6l_Y_dHLMUR"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "#from src.models.pytorch import get_device\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSEXx3chZow6"
   },
   "source": [
    "**[4.6]** Get the device available and set to the model to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBjzOC2IZo48"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (2 lines of Python code)\n",
    "# Task: Get the device available and set to the model to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pK5jUiV3Zo7l",
    "outputId": "e63808be-7170-4675-f313-35914fb8379a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextTopic(\n",
       "  (embedding): EmbeddingBag(6375026, 32, mode=mean)\n",
       "  (fc): Linear(in_features=32, out_features=14, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution:\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seG-TOa-Zv-i"
   },
   "source": [
    "**[4.7]** Print the architecture of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cB3ydX4jZwEO"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Print the architecture of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9PoOX-fZwGh",
    "outputId": "02358b56-9886-496b-89bc-159f28405c70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextTopic(\n",
       "  (embedding): EmbeddingBag(6375026, 32, mode=mean)\n",
       "  (fc): Linear(in_features=32, out_features=14, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution:\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUEbyrm2ZzhL"
   },
   "source": [
    "### 5. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faMubeDzZzuX"
   },
   "source": [
    "**[5.1]** Import DataLoader from torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSrYPUCPZz1u"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (multiple lines of Python code)\n",
    "# Task: Import train_binary and test_binary from src.models.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBSoR7LTZz3-"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORcJNo4ygaRa"
   },
   "source": [
    "**[5.2]** Create a function called `train_classification()` that will perform forward and back propagation and calculate loss and accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkXUqKMcgaZN"
   },
   "outputs": [],
   "source": [
    "def train_classification(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, generate_batch=None):\n",
    "    \"\"\"Train a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, offsets, target_class in data:\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature, offsets)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class.long())\n",
    "\n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate global accuracy\n",
    "        train_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), train_acc / len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBxCIn10ZDAF"
   },
   "source": [
    "**[5.3]** Create a function called `test_classification()` that will perform forward and calculate loss and accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLCzlF0xZDJ-"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (multiples lines of Python code)\n",
    "# Task: Create a function called test_classification() that will perform forward and calculate loss and accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6oNYKJEZDM4"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "def test_classification(test_data, model, criterion, batch_size, device, generate_batch=None):\n",
    "    \"\"\"Calculate performance of a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, offsets, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature, offsets)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class.long())\n",
    "\n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate global accuracy\n",
    "            test_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    return test_loss / len(test_data), test_acc / len(test_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR22BA8dZnKz"
   },
   "source": [
    "**[5.4]** Create a variable called `N_EPOCHS` that will take the value 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8UHBIMeZnTP"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (2 lines of Python code)\n",
    "# Task: Create a variable called N_EPOCHS that will take the value 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmw1xla2ZnYT"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhW6h_joh9OF"
   },
   "source": [
    "**[5.5]** Instantiate a `nn.CrossEntropyLoss()` and save it into a variable called `criterion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0NbBZBCh9WW"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Instantiate a nn.CrossEntropyLoss() and save it into a variable called criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH7ZZdZ_h9ZP"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oSSxPTGh9y7"
   },
   "source": [
    "**[5.6]** Instantiate a `torch.optim.SGD()` optimizer with the model's parameters and 4 as learning rate and save it into a variable called `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-yLLPXbh97Q"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (multiple lines of Python code)\n",
    "# Task: Instantiate a torch.optim.SGD() optimizer with the model's parameters and 4 as learning rate and save it into a variable called optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NlnOXwph99f"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRX1N4mriAFI"
   },
   "source": [
    "**[5.7]** Instantiate a `torch.optim.lr_scheduler.StepLR()` scheduler that will decrease the learning rate by a coefficient of 0.9 for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cog8RSz5iALL"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (multiple lines of Python code)\n",
    "# Task: Instantiate a torch.optim.lr_scheduler.StepLR() scheduler that will decrease the learning rate by a coefficient of 0.9 for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgdQyoWCjZWF"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekaUYYjqgfcF"
   },
   "source": [
    "**[5.8]** Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSzb5ZsYgfhf"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (multiples lines of Python code)\n",
    "# Task: Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8Jmfhk0MQ0i",
    "outputId": "b4417c71-7c19-41d7-c485-79d2b069afe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: 0.1343\t|\tAcc: 60.5%\n",
      "\t(valid)\t|\tLoss: 0.1289\t|\tAcc: 68.3%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: 0.1282\t|\tAcc: 69.2%\n",
      "\t(valid)\t|\tLoss: 0.1275\t|\tAcc: 70.1%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: 0.1271\t|\tAcc: 70.9%\n",
      "\t(valid)\t|\tLoss: 0.1271\t|\tAcc: 70.9%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: 0.1267\t|\tAcc: 71.6%\n",
      "\t(valid)\t|\tLoss: 0.1264\t|\tAcc: 72.2%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: 0.1264\t|\tAcc: 72.0%\n",
      "\t(valid)\t|\tLoss: 0.1263\t|\tAcc: 72.0%\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_data, model, criterion, optimizer, batch_size=BATCH_SIZE, device=device, scheduler=scheduler, generate_batch=generate_batch)\n",
    "    valid_loss, valid_acc = test_classification(valid_data, model, criterion, batch_size=BATCH_SIZE, device=device, generate_batch=generate_batch)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE8fVHin92-6"
   },
   "source": [
    "**[5.6]** Save the model into the `models` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAJZbmb-93Ge"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 line of Python code)\n",
    "# Task: Save the model into the models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oludTfN193I-"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "torch.save(model, \"../models/pytorch_dbpedia.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yX0Ocg4hcZM"
   },
   "source": [
    "### 6.   Push changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3guOKU9gjrmp"
   },
   "source": [
    "**[6.1]** Add you changes to git staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKuRNeqAj0ym"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Add you changes to git staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axcj-jS0jruy"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "git add ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nUK2dp_j67X"
   },
   "source": [
    "**[6.2]** Create the snapshot of your repository and add a description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-M-aS-Ij7EE"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Create the snapshot of your repository and add a description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zovhzXRxj7Il"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "git commit -m \"pytorch dbpedia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9FciIQZj7nX"
   },
   "source": [
    "**[6.3]** Push your snapshot to Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IR7i6D5hj7uO"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Push your snapshot to Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaVAgJ4Aj7wi"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7a6bwMniAs1"
   },
   "source": [
    "**[6.4]** Check out to the master branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eM9v_33XiA1I"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Check out to the master branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6-AI0x7iA4M"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "git checkout master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v98Ka9kNiBLw"
   },
   "source": [
    "**[6.5]** Pull the latest updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNZb1PyEjIOP"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Pull the latest updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TJAEYxPjIRS"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGd3Xdx-jJDk"
   },
   "source": [
    "**[6.6]** Check out to the `pytorch_dbpedia` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEYg8wauiBUb"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Merge the branch pytorch_dbpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNZunyVsiBXd"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "git checkout pytorch_bee_ant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjB_56bGdqpS"
   },
   "source": [
    "**[6.7]** Merge the `master` branch and push your changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q25rjnxTdqx5"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (2 command lines)\n",
    "# Task: Merge the master branch and push your changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTbrlcNzdq03"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "git merge master\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8B98cSvWkB-x"
   },
   "source": [
    "**[6.8]** Go to Github and merge the branch after reviewing the code and fixing any conflict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkQx18jYiEvQ"
   },
   "source": [
    "**[6.9]** Stop the Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlimZMQsiE7w"
   },
   "outputs": [],
   "source": [
    "# Placeholder for student's code (1 command line)\n",
    "# Task: Stop the Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovwOAbC5iE-T"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "docker stop adv_dsi_lab_6"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Advanced DS for Innovation - Lab 6 - Exercise 3 - Solutions",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
